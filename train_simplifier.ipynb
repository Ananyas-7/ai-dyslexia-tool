{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMFUZQYok5hFcsXP4+aF0Tt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananyas-7/ai-dyslexia-tool/blob/main/train_simplifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RehcyJGp79dQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets sentencepiece accelerate\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "# Choose model\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu easse textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QMX_INF_2fF",
        "outputId": "09e7d6f4-0fa3-484c-f9b0-d386e80e9e90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement easse (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for easse\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "valid = pd.read_csv(\"valid.csv\")\n",
        "print(train.head())\n",
        "print(valid.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAyT4sb29blG",
        "outputId": "7a8f2ae7-4fc8-42d9-aed6-88c034e1dd40"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          file                                           sentence  \\\n",
            "0  cesa109.pdf                  He has not finished his homework.   \n",
            "1  aemr104.pdf                              • Hide under a table.   \n",
            "2  aemr102.pdf                Mama sparrow laid three small eggs.   \n",
            "3  cesa101.pdf  Unit 1 Fun with Friends PPiiccttuurree rreeaad...   \n",
            "4  cesa107.pdf  3 4 5 Santoor │ Class 3 69 Reprint 2025-26 UUn...   \n",
            "\n",
            "                                    complex_sentence  \\\n",
            "0                  He has not finished his homework.   \n",
            "1                              • Hide under a table.   \n",
            "2                Mama sparrow laid three small eggs.   \n",
            "3  Unit 1 Fun with Friends PPiiccttuurree rreeaad...   \n",
            "4  3 4 5 Santoor │ Class 3 69 Reprint 2025-26 UUn...   \n",
            "\n",
            "                                              tokens  simple_sentence  \n",
            "0                               ha finished homework              NaN  \n",
            "1                                         hide table              NaN  \n",
            "2                  mama sparrow laid three small egg              NaN  \n",
            "3  unit fun friend ppiiccttuurree rreeaaddiinngg ...              NaN  \n",
            "4       santoor class reprint uunniitt iinndddd aamm              NaN  \n",
            "          file                                           sentence  \\\n",
            "0  cesa103.pdf  Children eat many sweets which are square in s...   \n",
            "1  aemr102.pdf             What things do you see in the picture?   \n",
            "2  cesa104.pdf       What do you call them in your mother tongue?   \n",
            "3  aemr107.pdf    Where do you sit when you have lunch at school?   \n",
            "4  cesa1ps.pdf  Reviewers Anurag Behar, CEO, Azim Premji Found...   \n",
            "\n",
            "                                    complex_sentence  \\\n",
            "0  Children eat many sweets which are square in s...   \n",
            "1             What things do you see in the picture?   \n",
            "2       What do you call them in your mother tongue?   \n",
            "3    Where do you sit when you have lunch at school?   \n",
            "4  Reviewers Anurag Behar, CEO, Azim Premji Found...   \n",
            "\n",
            "                                              tokens  simple_sentence  \n",
            "0                  child eat many sweet square shape              NaN  \n",
            "1                                  thing see picture              NaN  \n",
            "2                                 call mother tongue              NaN  \n",
            "3                                   sit lunch school              NaN  \n",
            "4  reviewer anurag behar ceo azim premji foundati...              NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTx4FRPtDxYq",
        "outputId": "11d793a6-7766-4860-b2b5-82baf45d7767"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_src = \"drive/MyDrive/ai-dyslexia-tool/data/raw/wikilarge/data-simplification/wikilarge/wiki.full.aner.ori.train.src\"\n",
        "train_dst = \"drive/MyDrive/ai-dyslexia-tool/data/raw/wikilarge/data-simplification/wikilarge/wiki.full.aner.ori.train.dst\"\n",
        "\n",
        "valid_src = \"drive/MyDrive/ai-dyslexia-tool/data/raw/wikilarge/data-simplification/wikilarge/wiki.full.aner.ori.valid.src\"\n",
        "valid_dst = \"drive/MyDrive/ai-dyslexia-tool/data/raw/wikilarge/data-simplification/wikilarge/wiki.full.aner.ori.valid.dst\"\n",
        "\n",
        "test_src = \"drive/MyDrive/ai-dyslexia-tool/data/raw/wikilarge/data-simplification/wikilarge/wiki.full.aner.ori.test.src\"\n",
        "test_dst = \"drive/MyDrive/ai-dyslexia-tool/data/raw/wikilarge/data-simplification/wikilarge/wiki.full.aner.ori.test.dst\""
      ],
      "metadata": {
        "id": "jdS8X8FwC0Vw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Training setup\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"models/t5_simplifier\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    learning_rate=3e-4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    save_total_limit=1,\n",
        "    predict_with_generate=True,\n",
        "    logging_steps=50,\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=2,\n",
        "    eval_steps=500,\n",
        "    save_steps=500,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=valid_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "W-Z2jWcj9jdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "from datasets import Dataset\n",
        "test_ds = Dataset.from_pandas(test)\n"
      ],
      "metadata": {
        "id": "VIbC8w4E9o1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the fine-tuned model\n",
        "model_dir = \"models/t5_simplifier\"\n",
        "simplifier = pipeline(\"text2text-generation\", model=model_dir, tokenizer=model_dir)\n",
        "preds = []\n",
        "for src in test[\"src\"]:\n",
        "    output = simplifier(\"simplify: \" + src, max_length=128, num_beams=4, clean_up_tokenization_spaces=True)[0]['generated_text']\n",
        "    preds.append(output)\n",
        "test[\"pred\"] = preds\n",
        "test.head()\n"
      ],
      "metadata": {
        "id": "sPDL4goL_wss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ntwXFmYQ_0T4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}